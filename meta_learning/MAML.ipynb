{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e36ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE = cpu\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "import glob, random\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "\n",
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "# Check device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"DEVICE = {device}\")\n",
    "\n",
    "# Fix random seeds\n",
    "random_seed = 42\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f75e1ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "n_way = 3\n",
    "k_shot = 1\n",
    "q_query = 5\n",
    "input_dim = 1280  # Adjust according to feature dimension\n",
    "train_inner_train_step = 5\n",
    "val_inner_train_step = 5\n",
    "inner_lr = 0.001\n",
    "meta_lr = 0.001\n",
    "meta_batch_size = 16\n",
    "max_epoch = 30\n",
    "eval_batches = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6545c50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Structure Overview:\n",
    "\n",
    "# Epoch Level (30 epochs)\n",
    "# │\n",
    "# ├── Meta-batch Level (16 batches per epoch)\n",
    "# │   │\n",
    "# │   ├── Task 1: [Abnormal A, Abnormal B, Normal] → [18, 1280] 18 = 3 categories * (1 support + 5 query); 1280 = feature dimension\n",
    "# │   ├── Task 2: [Abnormal C, Abnormal D, Normal] → [18, 1280] \n",
    "# │   ├── ...\n",
    "# │   └── Task 16: [Abnormal X, Abnormal Y, Normal] → [18, 1280]\n",
    "# │   │\n",
    "# │   └── Meta-batch: [16, 18, 1280]\n",
    "# │\n",
    "# └── How to process each Meta-batch in Solver(MAML Algorithm):\n",
    "#     │\n",
    "#     ├── Split Support/Query Set\n",
    "#     │   ├── Support: [16, 3, 1280]  (3 samples(1 for 3 categories) per task)\n",
    "#     │   └── Query:   [16, 15, 1280] (15 samples(5 for 3 categories) per task)\n",
    "#     │\n",
    "#     ├── Inner Training (5 steps, based on Support Set)\n",
    "#     │   └── Fast Adaptation: θ → θ'\n",
    "#     │\n",
    "#     ├── Outer Validation (based on Query Set)\n",
    "#     │   └── Compute meta-loss and accuracy\n",
    "#     │\n",
    "#     └── Outer Update (Meta-gradient)\n",
    "#         └── Update original parameters: θ ← θ - β∇_θ L_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9807cc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for labels and accuracy\n",
    "def create_malware_label(k_shot, q_query):\n",
    "    \"\"\"\n",
    "    Create labels for calculating accuracy in test phase.\n",
    "    3 classes: 2 abnormal + 1 normal\n",
    "    \"\"\"\n",
    "    n_way = 3  # 2 abnormal + 1 normal\n",
    "    labels = []\n",
    "    for class_idx in range(n_way):\n",
    "        class_labels = [class_idx] * (k_shot + q_query)\n",
    "        labels.extend(class_labels)\n",
    "    \n",
    "    return torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "def create_label(n_way, k_shot):\n",
    "    \"\"\"\n",
    "    Create labels for support set and query set.\n",
    "    \"\"\"\n",
    "    return torch.arange(n_way).repeat_interleave(k_shot).long()\n",
    "\n",
    "def calculate_accuracy(logits, labels):\n",
    "    \"\"\"utility function for accuracy calculation\"\"\"\n",
    "    acc = np.asarray(\n",
    "        [(torch.argmax(logits, -1).cpu().numpy() == labels.cpu().numpy())]\n",
    "    ).mean()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b70d03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MalwareClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=256, output_dim=3):\n",
    "        \"\"\"\n",
    "        A simple feedforward neural network for malware classification.\n",
    "        input_dim: 1280\n",
    "        output_dim: 3 (2 abnormal + 1 normal)\n",
    "        \"\"\"\n",
    "        super(MalwareClassifier, self).__init__()\n",
    "        \n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(), \n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, hidden_dim//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim//2, output_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "    \n",
    "    def functional_forward(self, x, params):\n",
    "        for i, (name, module) in enumerate(self.network.named_children()):\n",
    "            if isinstance(module, nn.Linear):\n",
    "                weight_key = f'network.{i}.weight'\n",
    "                bias_key = f'network.{i}.bias'\n",
    "                \n",
    "                x = F.linear(x, params.get(weight_key, module.weight), \n",
    "                           params.get(bias_key, module.bias))\n",
    "            elif isinstance(module, nn.ReLU):\n",
    "                x = F.relu(x)\n",
    "            elif isinstance(module, nn.Dropout):\n",
    "                x = F.dropout(x, training=self.training)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823c572c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Dataset\n",
    "class MalwareDetection(Dataset):\n",
    "    def __init__(self, data_structure_file, split='train', k_shot=1, q_query=5):\n",
    "        \"\"\"\n",
    "        Load dataset structure from JSON file.\n",
    "        \"\"\"\n",
    "        with open(data_structure_file, 'r') as f:\n",
    "            self.data_structure = json.load(f)\n",
    "        \n",
    "        self.split = split\n",
    "        self.classes = list(self.data_structure[split].keys())\n",
    "        self.k_shot = k_shot\n",
    "        self.q_query = q_query\n",
    "        self.normal_class = 'benign'\n",
    "        \n",
    "        self._validate_data()\n",
    "    \n",
    "    def _validate_data(self):\n",
    "        min_samples = self.k_shot + self.q_query\n",
    "        for cls, files in self.data_structure[self.split].items():\n",
    "            if len(files) < min_samples:\n",
    "                print(f\"Warning: only {len(files)} samples in class '{cls}' for split '{self.split}'. Required: {min_samples}. Will sample with replacement.\")\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        np.random.seed(42 + idx)  # Ensure reproducibility\n",
    "        \n",
    "        # Get available fraud classes\n",
    "        fraud_classes = [cls for cls in self.classes if cls != self.normal_class]\n",
    "        \n",
    "        if len(fraud_classes) >= 2:\n",
    "            selected_frauds = np.random.choice(fraud_classes, 2, replace=False)\n",
    "            task_classes = list(selected_frauds) + [self.normal_class]\n",
    "        elif len(fraud_classes) == 1:\n",
    "            if self.split == 'test':\n",
    "                task_classes = fraud_classes + [self.normal_class]\n",
    "            else:\n",
    "                task_classes = fraud_classes + fraud_classes + [self.normal_class]\n",
    "        else:\n",
    "            raise ValueError(f\"No fraud classes available in {self.split} split\")\n",
    "        \n",
    "        task_data = []\n",
    "        for cls in task_classes:\n",
    "            class_files = self.data_structure[self.split][cls]\n",
    "            \n",
    "            if len(class_files) >= self.k_shot + self.q_query:\n",
    "                selected_files = np.random.choice(class_files, \n",
    "                                                self.k_shot + self.q_query, \n",
    "                                                replace=False)\n",
    "            else:\n",
    "                selected_files = np.random.choice(class_files, \n",
    "                                                self.k_shot + self.q_query, \n",
    "                                                replace=True)\n",
    "                        \n",
    "            class_features = []\n",
    "            for file_path in selected_files:\n",
    "                corrected_path = self._fix_file_path(file_path)\n",
    "                \n",
    "                try:\n",
    "                    features = np.load(corrected_path)\n",
    "                    if features.ndim > 1:\n",
    "                        features = features.flatten()\n",
    "                    class_features.append(features)\n",
    "                except Exception as e:\n",
    "                    if idx == 0:\n",
    "                        print(f\"Error loading {corrected_path}: {e}\")\n",
    "                    class_features.append(np.zeros(1280))\n",
    "            \n",
    "            task_data.append(torch.tensor(np.array(class_features), dtype=torch.float32))\n",
    "        \n",
    "        return torch.stack(task_data)\n",
    "    \n",
    "    def _fix_file_path(self, original_path):\n",
    "        if os.path.exists(original_path):\n",
    "            return original_path\n",
    "        \n",
    "        possible_prefixes = ['../', '../../', './']\n",
    "        for prefix in possible_prefixes:\n",
    "            new_path = os.path.join(prefix, original_path)\n",
    "            if os.path.exists(new_path):\n",
    "                return os.path.abspath(new_path)\n",
    "        \n",
    "        return original_path\n",
    "    \n",
    "    def __len__(self):\n",
    "        fraud_classes = [cls for cls in self.classes if cls != self.normal_class]\n",
    "        if len(fraud_classes) >= 2:\n",
    "            from math import comb\n",
    "            return comb(len(fraud_classes), 2) * 100\n",
    "        else:\n",
    "            return 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "get_meta_batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meta_batch(meta_batch_size, k_shot, q_query, data_loader, iterator):\n",
    "    \"\"\"\n",
    "    Get meta batch function\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for _ in range(meta_batch_size):\n",
    "        try:\n",
    "            task_data = next(iterator)\n",
    "        except StopIteration:\n",
    "            iterator = iter(data_loader)\n",
    "            task_data = next(iterator)\n",
    "        \n",
    "        # task_data shape: [1, 3, k_shot+q_query, feature_dim]\n",
    "        # Transform to [3*(k_shot+q_query), feature_dim]\n",
    "        task_data = task_data.squeeze(0)  # [3, k_shot+q_query, feature_dim]\n",
    "        task_data = task_data.view(-1, task_data.size(-1))  # [3*(k_shot+q_query), feature_dim]\n",
    "        data.append(task_data)\n",
    "    \n",
    "    return torch.stack(data).to(device), iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solver_function",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main MAML Algorithm\n",
    "def Solver(\n",
    "    model,\n",
    "    optimizer,\n",
    "    x,\n",
    "    n_way,\n",
    "    k_shot,\n",
    "    q_query,\n",
    "    loss_fn,\n",
    "    inner_train_step,\n",
    "    inner_lr,\n",
    "    train,\n",
    "    return_labels=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Main MAML algorithm\n",
    "    \"\"\"\n",
    "    criterion = loss_fn\n",
    "    task_loss = []\n",
    "    task_acc = []\n",
    "    labels = []\n",
    "    \n",
    "    for meta_batch in x:\n",
    "        # Split support and query sets\n",
    "        support_set = meta_batch[: n_way * k_shot]\n",
    "        query_set = meta_batch[n_way * k_shot :]\n",
    "\n",
    "        # Copy the params for inner loop\n",
    "        fast_weights = OrderedDict(model.named_parameters())\n",
    "\n",
    "        ### ---------- INNER TRAIN LOOP ---------- ###\n",
    "        for inner_step in range(inner_train_step):\n",
    "            # Simply training\n",
    "            train_label = create_label(n_way, k_shot).to(device)\n",
    "            logits = model.functional_forward(support_set, fast_weights)\n",
    "            loss = criterion(logits, train_label)\n",
    "            # Inner gradients update!\n",
    "            # Calculate gradients\n",
    "            grads = torch.autograd.grad(loss, fast_weights.values(), create_graph=True)\n",
    "\n",
    "            # Update fast_weights\n",
    "            # θ' = θ - α * ∇loss\n",
    "            fast_weights = OrderedDict(\n",
    "                (name, param - inner_lr * grad)\n",
    "                for ((name, param), grad) in zip(fast_weights.items(), grads)\n",
    "            )\n",
    "\n",
    "        ### ---------- INNER VALID LOOP ---------- ###\n",
    "        if not return_labels:\n",
    "            \"\"\" training / validation \"\"\"\n",
    "            val_label = create_label(n_way, q_query).to(device)\n",
    "\n",
    "            # Collect gradients for outer loop\n",
    "            logits = model.functional_forward(query_set, fast_weights)\n",
    "            loss = criterion(logits, val_label)\n",
    "            task_loss.append(loss)\n",
    "            task_acc.append(calculate_accuracy(logits, val_label))\n",
    "        else:\n",
    "            \"\"\" testing \"\"\"\n",
    "            logits = model.functional_forward(query_set, fast_weights)\n",
    "            labels.extend(torch.argmax(logits, -1).cpu().numpy())\n",
    "\n",
    "    if return_labels:\n",
    "        return labels\n",
    "\n",
    "    # Update outer loop\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    meta_batch_loss = torch.stack(task_loss).mean()\n",
    "    if train:\n",
    "        \"\"\" Outer Loop Update \"\"\"\n",
    "        # φ backpropagation\n",
    "        meta_batch_loss.backward()\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "    task_acc = np.mean(task_acc)\n",
    "    return meta_batch_loss, task_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04971fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 427011\n"
     ]
    }
   ],
   "source": [
    "# Prepare datasets and dataloaders\n",
    "train_dataset = MalwareDetection('../malware_data_structure.json', 'train', k_shot, q_query)\n",
    "val_dataset = MalwareDetection('../malware_data_structure.json', 'val', k_shot, q_query)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Create model, optimizer, and loss function\n",
    "meta_model = MalwareClassifier(input_dim=input_dim).to(device)\n",
    "optimizer = torch.optim.Adam(meta_model.parameters(), lr=meta_lr)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "print(f\"Model parameters: {sum(p.numel() for p in meta_model.parameters())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "training_loop",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 62/62 [00:11<00:00,  5.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.961\tAccuracy: 50.094%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00, 10.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 45.903%\n",
      "--------------------------------------------------\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 62/62 [00:09<00:00,  6.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.890\tAccuracy: 54.126%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00, 12.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 48.681%\n",
      "--------------------------------------------------\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 62/62 [00:09<00:00,  6.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.872\tAccuracy: 55.034%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00, 16.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 48.750%\n",
      "--------------------------------------------------\n",
      "Epoch 4/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 62/62 [00:09<00:00,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.860\tAccuracy: 55.927%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00, 15.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 48.403%\n",
      "--------------------------------------------------\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 62/62 [00:09<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.858\tAccuracy: 55.860%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00, 15.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 48.542%\n",
      "--------------------------------------------------\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 62/62 [00:09<00:00,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.842\tAccuracy: 56.640%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00, 15.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 50.486%\n",
      "--------------------------------------------------\n",
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 62/62 [00:10<00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.837\tAccuracy: 57.077%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00, 16.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 49.028%\n",
      "--------------------------------------------------\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 62/62 [00:09<00:00,  6.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.835\tAccuracy: 57.547%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00, 16.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 48.750%\n",
      "--------------------------------------------------\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 62/62 [00:09<00:00,  6.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.828\tAccuracy: 57.527%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00, 15.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 48.056%\n",
      "--------------------------------------------------\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 62/62 [00:09<00:00,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.826\tAccuracy: 57.587%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00, 16.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 49.722%\n",
      "--------------------------------------------------\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 62/62 [00:09<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.819\tAccuracy: 57.776%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00, 16.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 50.764%\n",
      "--------------------------------------------------\n",
      "Epoch 12/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 62/62 [00:09<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.817\tAccuracy: 58.192%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00, 16.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 50.000%\n",
      "--------------------------------------------------\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 62/62 [00:09<00:00,  6.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.818\tAccuracy: 58.542%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00, 15.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 49.722%\n",
      "--------------------------------------------------\n",
      "Epoch 14/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 62/62 [00:10<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.817\tAccuracy: 58.185%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00, 12.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 49.097%\n",
      "--------------------------------------------------\n",
      "Epoch 15/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 62/62 [00:09<00:00,  6.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.810\tAccuracy: 58.589%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00, 15.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 51.181%\n",
      "--------------------------------------------------\n",
      "Epoch 16/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 62/62 [00:09<00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.810\tAccuracy: 58.515%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00, 14.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 49.722%\n",
      "--------------------------------------------------\n",
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 62/62 [00:10<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.804\tAccuracy: 58.790%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00, 16.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 51.875%\n",
      "--------------------------------------------------\n",
      "Epoch 18/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 62/62 [00:09<00:00,  6.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.805\tAccuracy: 58.542%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00, 14.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 51.250%\n",
      "--------------------------------------------------\n",
      "Epoch 19/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 62/62 [00:09<00:00,  6.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.797\tAccuracy: 58.898%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00, 15.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 50.625%\n",
      "--------------------------------------------------\n",
      "Epoch 20/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 62/62 [00:09<00:00,  6.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.802\tAccuracy: 59.073%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00, 15.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 50.000%\n",
      "--------------------------------------------------\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 62/62 [00:08<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.803\tAccuracy: 58.797%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00, 16.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 49.861%\n",
      "--------------------------------------------------\n",
      "Epoch 22/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 62/62 [00:08<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.799\tAccuracy: 59.328%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00, 16.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 50.417%\n",
      "--------------------------------------------------\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 62/62 [00:09<00:00,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.804\tAccuracy: 58.750%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00, 15.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 50.486%\n",
      "--------------------------------------------------\n",
      "Epoch 24/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 62/62 [00:08<00:00,  7.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.794\tAccuracy: 59.173%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00, 16.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 50.139%\n",
      "--------------------------------------------------\n",
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 62/62 [00:09<00:00,  6.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.793\tAccuracy: 59.214%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00, 15.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 50.208%\n",
      "--------------------------------------------------\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 62/62 [00:08<00:00,  7.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.787\tAccuracy: 59.435%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00, 15.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 50.139%\n",
      "--------------------------------------------------\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 62/62 [00:09<00:00,  6.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.787\tAccuracy: 59.610%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00, 15.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 50.486%\n",
      "--------------------------------------------------\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 62/62 [00:09<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.781\tAccuracy: 59.872%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00, 16.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 50.000%\n",
      "--------------------------------------------------\n",
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 62/62 [00:09<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.782\tAccuracy: 59.792%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00, 15.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 48.958%\n",
      "--------------------------------------------------\n",
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 62/62 [00:09<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.783\tAccuracy: 59.603%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6/6 [00:00<00:00, 15.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 50.625%\n",
      "--------------------------------------------------\n",
      "Done！\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "train_iter = iter(train_loader)\n",
    "val_iter = iter(val_loader)\n",
    "\n",
    "print(\"Starting training...\")\n",
    "for epoch in range(max_epoch):\n",
    "    print(f\"Epoch {epoch+1}/{max_epoch}\")\n",
    "    \n",
    "    # Training\n",
    "    train_meta_loss = []\n",
    "    train_acc = []\n",
    "    \n",
    "    for train_step in tqdm(range(len(train_loader) // meta_batch_size), desc=\"Training\"):\n",
    "        x, train_iter = get_meta_batch(\n",
    "            meta_batch_size, k_shot, q_query, train_loader, train_iter\n",
    "        )\n",
    "        \n",
    "        meta_loss, acc = Solver(\n",
    "            meta_model,\n",
    "            optimizer,\n",
    "            x,\n",
    "            n_way,\n",
    "            k_shot,\n",
    "            q_query,\n",
    "            loss_fn,\n",
    "            inner_train_step=train_inner_train_step,\n",
    "            inner_lr=inner_lr,\n",
    "            train=True,\n",
    "        )\n",
    "        \n",
    "        train_meta_loss.append(meta_loss.item())\n",
    "        train_acc.append(acc)\n",
    "    \n",
    "    print(f\"Loss: {np.mean(train_meta_loss):.3f}\\tAccuracy: {np.mean(train_acc)*100:.3f}%\")\n",
    "    \n",
    "    # Validation\n",
    "    val_acc = []\n",
    "    for eval_step in tqdm(range(min(eval_batches, len(val_loader) // meta_batch_size)), desc=\"Validation\"):\n",
    "        x, val_iter = get_meta_batch(\n",
    "            meta_batch_size, k_shot, q_query, val_loader, val_iter\n",
    "        )\n",
    "        \n",
    "        _, acc = Solver(\n",
    "            meta_model,\n",
    "            optimizer,\n",
    "            x,\n",
    "            n_way,\n",
    "            k_shot,\n",
    "            q_query,\n",
    "            loss_fn,\n",
    "            inner_train_step=val_inner_train_step,\n",
    "            inner_lr=inner_lr,\n",
    "            train=False,\n",
    "        )\n",
    "        val_acc.append(acc)\n",
    "    \n",
    "    print(f\"Validation accuracy: {np.mean(val_acc)*100:.3f}%\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "print(\"Done！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "save_model",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as malware_maml_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "torch.save({\n",
    "    'model_state_dict': meta_model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'hyperparameters': {\n",
    "        'n_way': n_way,\n",
    "        'k_shot': k_shot,\n",
    "        'q_query': q_query,\n",
    "        'input_dim': input_dim,\n",
    "        'inner_lr': inner_lr,\n",
    "        'meta_lr': meta_lr\n",
    "    }\n",
    "}, 'malware_maml_model.pth')\n",
    "\n",
    "print(\"Model saved as malware_maml_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e59ff63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting testing and accuracy calculation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing with Accuracy:   5%|▌         | 1/20 [00:00<00:05,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1/20 - Task Accuracy: 0.4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing with Accuracy:  30%|███       | 6/20 [00:01<00:04,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6/20 - Task Accuracy: 0.5333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing with Accuracy:  55%|█████▌    | 11/20 [00:03<00:02,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 11/20 - Task Accuracy: 0.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing with Accuracy:  80%|████████  | 16/20 [00:05<00:01,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 16/20 - Task Accuracy: 0.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing with Accuracy: 100%|██████████| 20/20 [00:06<00:00,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Task Accuracy: 32.667%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def test_model(model, test_data_path_or_dataset, inner_train_step=500):\n",
    "    \"\"\"\n",
    "    Test function that returns predicted and true labels for accuracy calculation\n",
    "    3-way tasks: 2 abnormal + 1 normal\n",
    "    \"\"\"\n",
    "    test_dataset = MalwareDetection(test_data_path_or_dataset, 'test', k_shot, q_query)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "    test_iter = iter(test_loader)\n",
    "    \n",
    "    test_batches = min(20, len(test_loader))\n",
    "    all_predicted_labels = []\n",
    "    all_true_labels = []\n",
    "    task_accuracies = []\n",
    "\n",
    "    print(\"Starting testing and accuracy calculation...\")\n",
    "\n",
    "    # Fix random seed for consistent label generation\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    for batch_idx in tqdm(range(test_batches), desc=\"Testing with Accuracy\"):\n",
    "        x, test_iter = get_meta_batch(1, k_shot, q_query, test_loader, test_iter)\n",
    "\n",
    "        # Check the actual task dimensions\n",
    "        batch_size, total_samples, feature_dim = x.shape\n",
    "        actual_n_way = total_samples // (k_shot + q_query)\n",
    "\n",
    "        # 3-way task query set labels\n",
    "        task_true_labels = []\n",
    "        for class_idx in range(3):\n",
    "            task_true_labels.extend([class_idx] * q_query)\n",
    "\n",
    "        # Get model predictions\n",
    "        predicted_labels = Solver(\n",
    "            model,\n",
    "            optimizer,\n",
    "            x,\n",
    "            3,  \n",
    "            k_shot,\n",
    "            q_query,\n",
    "            loss_fn,\n",
    "            inner_train_step=inner_train_step,\n",
    "            inner_lr=inner_lr,\n",
    "            train=False,\n",
    "            return_labels=True,\n",
    "        )\n",
    "\n",
    "        # Calculate current task accuracy\n",
    "        task_true = np.array(task_true_labels)\n",
    "        task_pred = np.array(predicted_labels)\n",
    "        task_acc = (task_true == task_pred).mean()\n",
    "        task_accuracies.append(task_acc)\n",
    "\n",
    "        # Collect all labels\n",
    "        all_predicted_labels.extend(predicted_labels)\n",
    "        all_true_labels.extend(task_true_labels)\n",
    "\n",
    "        if batch_idx % 5 == 0:  # Print every 5 batches\n",
    "            print(f\"Batch {batch_idx+1}/{test_batches} - Task Accuracy: {task_acc:.4f}\")\n",
    "    \n",
    "    return all_predicted_labels, all_true_labels, task_accuracies\n",
    "\n",
    "# Execute improved testing with accuracy calculation\n",
    "test_predicted_labels, test_true_labels, test_task_accuracies = test_model(meta_model, '../malware_data_structure.json')\n",
    "average_test_accuracy = np.mean(test_task_accuracies)\n",
    "print(f\"Average Test Task Accuracy: {average_test_accuracy*100:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "save_results",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results saved as malware_maml_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Save test results\n",
    "results_df = pd.DataFrame({\n",
    "    'id': range(len(test_predicted_labels)),\n",
    "    'predicted_class': test_predicted_labels,\n",
    "    'true_class': test_true_labels\n",
    "})\n",
    "\n",
    "results_df.to_csv('malware_maml_predictions.csv', index=False)\n",
    "print(\"Test results saved as malware_maml_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baca63d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
